{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPmn5oY1VNyDU6Sy8AHKF3v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KKGrLGuVoCBM"},"outputs":[],"source":["# Google Colab에서 노트북을 실행하실 때에는\n","# https://tutorials.pytorch.kr/beginner/colab 를 참고하세요.\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"Ea_fVdqDoCBO"},"source":["`nn.Transformer` 와 torchtext로 시퀀스-투-시퀀스(Sequence-to-Sequence) 모델링하기\n","=================================================================================\n","\n","이 튜토리얼에서는\n","[nn.Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)\n","모듈을 이용하는 시퀀스-투-시퀀스(Sequence-to-Sequence) 모델을 학습하는\n","방법을 배워보겠습니다.\n","\n","PyTorch 1.2 버젼에는 [Attention is All You\n","Need](https://arxiv.org/pdf/1706.03762.pdf) 논문에 기반한 표준\n","트랜스포머(transformer) 모듈을 포함하고 있습니다. 트랜스포머 모델은\n","다양한 시퀀스-투-시퀀스 문제들에서 더 병렬화(parallelizable)가\n","가능하면서도 순환 신경망(RNN; Recurrent Neural Network)과 비교하여 더\n","나은 성능을 보임이 입증되었습니다. `nn.Transformer` 모듈은 입력(input)\n","과 출력(output) 사이의 전역적인 의존성(global dependencies) 을 나타내기\n","위하여\n","([nn.MultiheadAttention](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html)\n","으로 구현된) 어텐션(attention) 메커니즘에 전적으로 의존합니다. 현재\n","`nn.Transformer` 모듈은 모듈화가 잘 되어 있어 단일 컴포넌트 (예.\n","[nn.TransformerEncoder](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html)\n",") 로 쉽게 적용 및 구성할 수 있습니다.\n","\n","![image](https://tutorials.pytorch.kr/_static/img/transformer_architecture.jpg)\n"]},{"cell_type":"markdown","metadata":{"id":"LokySHuxoCBQ"},"source":["모델 정의하기\n","=============\n"]},{"cell_type":"markdown","metadata":{"id":"7x_TCvlaoCBR"},"source":["이 튜토리얼에서, 우리는 `nn.TransformerEncoder` 모델을 언어\n","모델링(language modeling) 과제에 대해서 학습시킬 것입니다. 언어 모델링\n","과제는 주어진 단어 (또는 단어의 시퀀스) 가 다음에 이어지는 단어 시퀀스를\n","따를 가능성(likelihood)에 대한 확률을 할당하는 것입니다. 먼저,\n","토큰(token) 들의 시퀀스가 임베딩(embedding) 레이어로 전달되며, 이어서\n","포지셔널 인코딩(positional encoding) 레이어가 각 단어의 순서를\n","설명합니다. (더 자세한 설명은 다음 단락을 참고해주세요.)\n","`nn.TransformerEncoder` 는 여러 개의\n","[nn.TransformerEncoderLayer](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html)\n","레이어로 구성되어 있습니다. `nn.TransformerEncoder` 내부의\n","셀프-어텐션(self-attention) 레이어들은 시퀀스 안에서의 이전 포지션에만\n","집중하도록 허용되기 때문에, 입력(input) 순서와 함께, 정사각 형태의\n","어텐션 마스크(attention mask) 가 필요합니다. 언어 모델링 과제를 위해서,\n","미래의 포지션에 있는 모든 토큰들은 마스킹 되어야(가려져야) 합니다. 실제\n","단어를 얻기 위해서, `nn.TransformerEncoder` 의 출력은\n","로그-소프트맥스(log-Softmax) 로 이어지는 최종 선형(Linear) 레이어로 전달\n","됩니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_YEJb7RoCBR"},"outputs":[],"source":["import math\n","import os\n","from tempfile import TemporaryDirectory\n","from typing import Tuple\n","\n","import torch\n","from torch import nn, Tensor\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","from torch.utils.data import dataset\n","\n","class TransformerModel(nn.Module):\n","\n","    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n","                 nlayers: int, dropout: float = 0.5):\n","        super().__init__()\n","        self.model_type = 'Transformer'\n","        self.pos_encoder = PositionalEncoding(d_model, dropout)\n","        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(ntoken, d_model)\n","        self.d_model = d_model\n","        self.decoder = nn.Linear(d_model, ntoken)\n","\n","        self.init_weights()\n","\n","    def init_weights(self) -> None:\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n","        \"\"\"\n","        Arguments:\n","            src: Tensor, shape ``[seq_len, batch_size]``\n","            src_mask: Tensor, shape ``[seq_len, seq_len]``\n","\n","        Returns:\n","            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n","        \"\"\"\n","        src = self.encoder(src) * math.sqrt(self.d_model)\n","        src = self.pos_encoder(src)\n","        output = self.transformer_encoder(src, src_mask)\n","        output = self.decoder(output)\n","        return output\n","\n","\n","def generate_square_subsequent_mask(sz: int) -> Tensor:\n","    \"\"\"Generates an upper-triangular matrix of ``-inf``, with zeros on ``diag``.\"\"\"\n","    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"]},{"cell_type":"markdown","metadata":{"id":"vCBlgrYNoCBS"},"source":["`PositionalEncoding` 모듈은 시퀀스 안에서 토큰의 상대적인 또는 절대적인\n","포지션에 대한 어떤 정보를 주입합니다. 포지셔널 인코딩은 임베딩과 합칠 수\n","있도록 똑같은 차원을 가집니다. 여기에서, 우리는 다른 주파수(frequency)\n","의 `sine` 과 `cosine` 함수를 사용합니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4WK2TzzBoCBS"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"\n","        Arguments:\n","            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n","        \"\"\"\n","        x = x + self.pe[:x.size(0)]\n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"iIte8KEJoCBT"},"source":["데이터 로드하고 배치 만들기\n","===========================\n"]},{"cell_type":"markdown","metadata":{"id":"tvGc8lNRoCBT"},"source":["이 튜토리얼에서는 `torchtext` 를 사용하여 Wikitext-2 데이터셋을\n","생성합니다. torchtext 데이터셋에 접근하기 전에,\n","<https://github.com/pytorch/data> 을 참고하여 torchdata를 설치하시기\n","바랍니다. %% .. code-block:: bash\n","\n","> \\%%bash pip install torchdata\n","\n","어휘(vocab) 객체는 훈련 데이터셋(train dataset) 에 의하여 만들어지고,\n","토큰(token)을 텐서(tensor)로 수치화하는데 사용됩니다. Wikitext-2에서\n","보기 드문 토큰(rare token)은 [\\<unk\\>]{.title-ref} 로 표현됩니다.\n","\n","주어진 1D 벡터의 시퀀스 데이터에서, `batchify()` 함수는 데이터를\n","`batch_size` 컬럼들로 정렬합니다. 만약 데이터가 `batch_size` 컬럼으로\n","나누어 떨어지지 않으면, 데이터를 잘라내서 맞춥니다. 예를 들어 (총 길이\n","26의) 알파벳을 데이터로 보고 `batch_size=4` 일 때, 알파벳은 길이가 6인\n","4개의 시퀀스로 나눠집니다:\n","\n","$$\\begin{aligned}\n","\\begin{bmatrix}\n","\\text{A} & \\text{B} & \\text{C} & \\ldots & \\text{X} & \\text{Y} & \\text{Z}\n","\\end{bmatrix}\n","\\Rightarrow\n","\\begin{bmatrix}\n","\\begin{bmatrix}\\text{A} \\\\ \\text{B} \\\\ \\text{C} \\\\ \\text{D} \\\\ \\text{E} \\\\ \\text{F}\\end{bmatrix} &\n","\\begin{bmatrix}\\text{G} \\\\ \\text{H} \\\\ \\text{I} \\\\ \\text{J} \\\\ \\text{K} \\\\ \\text{L}\\end{bmatrix} &\n","\\begin{bmatrix}\\text{M} \\\\ \\text{N} \\\\ \\text{O} \\\\ \\text{P} \\\\ \\text{Q} \\\\ \\text{R}\\end{bmatrix} &\n","\\begin{bmatrix}\\text{S} \\\\ \\text{T} \\\\ \\text{U} \\\\ \\text{V} \\\\ \\text{W} \\\\ \\text{X}\\end{bmatrix}\n","\\end{bmatrix}\n","\\end{aligned}$$\n","\n","배치 작업(batching)은 더 많은 병렬 처리를 가능하게 하지만, 모델이\n","독립적으로 각 컬럼들을 취급해야 함을 뜻합니다; 예를 들어, 위 예제에서\n","`G` 와 `F` 의 의존성(dependance)은 학습되지 않습니다.\n"]},{"cell_type":"markdown","source":["# from torchtext.datasets import WikiText2 오류\n","\n","https://tutorials.pytorch.kr/beginner/transformer_tutorial.html 에서의 WikiText2 로드 오류\n","\n","## => 직접 train.txt, test.txt keggle에서 다운로드 받아서 실행\n","\n","https://www.kaggle.com/datasets/vivekmettu/wikitext2-data?phase=FinishSSORegistration&returnUrl=/datasets/vivekmettu/wikitext2-data/versions/1?resource=download&SSORegistrationToken=CfDJ8GXdT74sZy9Iv4qC0qaf2Re_dQolah2sWodbYmdlggcjjJ05s_i3h4iaqhA6E77zqZtVxZbfqZQ9UQpBewgut6p2_02mUelrvk-aYtXP11b1GOIWQ1n8xQMYElm0L8RUwCHv08o9_TZMU9DicciPEDMJ2GPLpqIXqqYA4k25xiIPsiaQSwZ1zE4cGTQpAcVo3HouISc2IWLcGGhAOvF5fT0X2h0ZbMT_GqdG-n0IZc7K3BxYSknPWKX2VXA6cwfwA1OUx-psWuyRrfAkcBNuvZq0Jx_UbCmRmANCdMP1-cHhUHBfdlEsrJ4VucqpKYn3xqvMkwFchPJImeS8XRaFWpH1&DisplayName=SEMINI\n","\n","\n","\n","1. **파일 불러오기**:\n","   - `train.txt`, `test.txt` 파일을 읽고, 이를 토큰화하여 텐서로 변환하는 `data_process()` 함수를 작성\n","   \n","2. **어휘 사전 생성**:\n","   - `yield_tokens()` 함수로 `train.txt` 파일의 데이터를 토큰화하고, 이를 기반으로 어휘 사전 생성\n","\n","3. **데이터 배치화**:\n","   - `batchify()` 함수는 데이터를 배치 크기에 맞게 나누어 처리할 수 있도록 텐서 형태로 변환\n","\n","4. **배치 크기 설정**:\n","   - `train_data`와 `test_data`를 배치 단위로 변환하여 모델 학습에 사용할 준비 완료\n","\n","이 코드를 사용하면 `train.txt`와 `test.txt` 파일의 데이터를 토큰화하고, 이를 텐서 형태로 변환해 배치로 나눌 수 있음\n","\n"],"metadata":{"id":"mxHUoIf7IKYB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"favojagOoCBU","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"error","timestamp":1725870618840,"user_tz":-540,"elapsed":12,"user":{"displayName":"SEMINI","userId":"03287729569136471451"}},"outputId":"1cbccd91-12eb-41ac-fbdc-bd5208e48a37"},"outputs":[{"output_type":"error","ename":"OSError","evalue":"/usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-4df8c96e2466>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWikiText2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# the following import has to happen first in order to load the torchtext C++ library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_TEXT_BUCKET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://download.pytorch.org/models/text/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchtext C++ Extension is not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtorchtext\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# This import is for initializing the methods registered via PyBind11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# This has to happen after the base library is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"]}],"source":["import torch\n","from torch import Tensor\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","# 파일 경로 설정\n","train_file_path = './train.txt'\n","test_file_path = './test.txt'\n","\n","# Tokenizer 설정\n","tokenizer = get_tokenizer('basic_english')\n","\n","# 텍스트 파일을 읽어들이고 라인별로 토큰화\n","def yield_tokens(file_path, tokenizer):\n","    with open(file_path, encoding='utf-8') as f:\n","        for line in f:\n","            yield tokenizer(line)\n","\n","# 어휘 사전 구축\n","vocab = build_vocab_from_iterator(yield_tokens(train_file_path, tokenizer), specials=['<unk>'])\n","vocab.set_default_index(vocab['<unk>'])\n","\n","# 데이터를 처리하는 함수\n","def data_process(file_path: str, tokenizer, vocab) -> Tensor:\n","    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n","    data = []\n","    with open(file_path, encoding='utf-8') as f:\n","        for line in f:\n","            tokens = tokenizer(line)\n","            token_ids = vocab(tokens)\n","            tensor = torch.tensor(token_ids, dtype=torch.long)\n","            if tensor.numel() > 0:\n","                data.append(tensor)\n","    return torch.cat(data)\n","\n","# 데이터를 처리하여 텐서로 변환\n","train_data = data_process(train_file_path, tokenizer, vocab)\n","test_data = data_process(test_file_path, tokenizer, vocab)\n","\n","# 배치 데이터를 나누는 함수\n","def batchify(data: Tensor, bsz: int) -> Tensor:\n","    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n","    that wouldn't cleanly fit.\n","\n","    Arguments:\n","        data: Tensor, shape ``[N]``\n","        bsz: int, batch size\n","\n","    Returns:\n","        Tensor of shape ``[N // bsz, bsz]``\n","    \"\"\"\n","    seq_len = data.size(0) // bsz\n","    data = data[:seq_len * bsz]  # 추가적인 데이터를 잘라냄\n","    data = data.view(bsz, seq_len).t().contiguous()  # 데이터를 배치로 변환\n","    return data.to(device)\n","\n","# 디바이스 설정 (CUDA 사용 가능 여부 확인)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# 배치 크기 설정\n","batch_size = 20\n","eval_batch_size = 10\n","\n","# 배치화된 데이터 생성\n","train_data = batchify(train_data, batch_size)\n","test_data = batchify(test_data, eval_batch_size)\n","\n","print(f\"Train data shape: {train_data.shape}\")\n","print(f\"Test data shape: {test_data.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"AJxLaaInoCBU"},"source":["입력(input) 과 타겟(target) 시퀀스를 생성하기 위한 함수들\n","=========================================================\n"]},{"cell_type":"markdown","metadata":{"id":"ie7hz7G1oCBU"},"source":["`get_batch()` 함수는 트랜스포머 모델을 위한 입력-타겟 시퀀스 쌍(pair)을\n","생성합니다. 이 함수는 소스 데이터를 `bptt` 길이를 가진 덩어리로 세분화\n","합니다. 언어 모델링 과제를 위해서, 모델은 다음 단어인 `Target` 이 필요\n","합니다. 예를 들어, `bptt` 의 값이 2 라면, 우리는 `i` = 0 일 때 다음의 2\n","개의 변수(Variable) 를 얻을 수 있습니다:\n","\n","![image](https://tutorials.pytorch.kr/_static/img/transformer_input_target.png)\n","\n","변수 덩어리는 트랜스포머 모델의 `S` 차원과 일치하는 0 차원에 해당합니다.\n","배치 차원 `N` 은 1 차원에 해당합니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjrQgBKeoCBU"},"outputs":[],"source":["bptt = 35\n","def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n","    \"\"\"\n","    Arguments:\n","        source: Tensor, shape ``[full_seq_len, batch_size]``\n","        i: int\n","\n","    Returns:\n","        tuple ``(data, target)``, where data has shape ``[seq_len, batch_size]`` and\n","        target has shape ``[seq_len * batch_size]``\n","    \"\"\"\n","    seq_len = min(bptt, len(source) - 1 - i)\n","    data = source[i:i+seq_len]\n","    target = source[i+1:i+1+seq_len].reshape(-1)\n","    return data, target"]},{"cell_type":"markdown","metadata":{"id":"tZIZO99foCBV"},"source":["인스턴스(instance) 초기화하기\n","=============================\n"]},{"cell_type":"markdown","metadata":{"id":"_a2cwtJ0oCBV"},"source":["모델의 하이퍼파라미터(hyperparameter)는 아래와 같이 정의됩니다. 어휘집(\n","`vocab` )의 크기는 단어 오브젝트의 길이와 일치 합니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hiCvr5a3oCBV"},"outputs":[],"source":["ntokens = len(vocab) # 단어 사전(어휘집)의 크기\n","emsize = 200 # 임베딩 차원\n","d_hid = 200 # ``nn.TransformerEncoder`` 에서 피드포워드 네트워크(feedforward network) 모델의 차원\n","nlayers = 2 # ``nn.TransformerEncoder`` 내부의 nn.TransformerEncoderLayer 개수\n","nhead = 2 # ``nn.MultiheadAttention`` 의 헤드 개수\n","dropout = 0.2 # 드랍아웃(dropout) 확률\n","model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"]},{"cell_type":"markdown","metadata":{"id":"DV8OB4gkoCBV"},"source":["모델 실행하기\n","=============\n"]},{"cell_type":"markdown","metadata":{"id":"8WtFtyhsoCBV"},"source":["[CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n","를 [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)\n","(확률적 경사 하강법) 옵티마이저(optimizer)와 함께 사용하였습니다.\n","학습률(learning rate)는 5.0으로 초기화하였으며\n","[StepLR](https://pytorch.org/docs/master/optim.html?highlight=steplr#torch.optim.lr_scheduler.StepLR)\n","스케쥴을 따릅니다. 학습하는 동안,\n","[nn.utils.clip\\_grad\\_norm\\_](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n","을 사용하여 기울기(gradient)가 폭발(exploding)하지 않도록 합니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BX1BpFGCoCBV"},"outputs":[],"source":["import copy\n","import time\n","\n","criterion = nn.CrossEntropyLoss()\n","lr = 5.0  # 학습률(learning rate)\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n","\n","def train(model: nn.Module) -> None:\n","    model.train()  # 학습 모드 시작\n","    total_loss = 0.\n","    log_interval = 200\n","    start_time = time.time()\n","    src_mask = generate_square_subsequent_mask(bptt).to(device)\n","\n","    num_batches = len(train_data) // bptt\n","    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n","        data, targets = get_batch(train_data, i)\n","        seq_len = data.size(0)\n","        if seq_len != bptt:  # 마지막 배치에만 적용\n","            src_mask = src_mask[:seq_len, :seq_len]\n","        output = model(data, src_mask)\n","        loss = criterion(output.view(-1, ntokens), targets)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        if batch % log_interval == 0 and batch > 0:\n","            lr = scheduler.get_last_lr()[0]\n","            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n","            cur_loss = total_loss / log_interval\n","            ppl = math.exp(cur_loss)\n","            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n","                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n","                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n","            total_loss = 0\n","            start_time = time.time()\n","\n","def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n","    model.eval()  # 평가 모드 시작\n","    total_loss = 0.\n","    src_mask = generate_square_subsequent_mask(bptt).to(device)\n","    with torch.no_grad():\n","        for i in range(0, eval_data.size(0) - 1, bptt):\n","            data, targets = get_batch(eval_data, i)\n","            seq_len = data.size(0)\n","            if seq_len != bptt:\n","                src_mask = src_mask[:seq_len, :seq_len]\n","            output = model(data, src_mask)\n","            output_flat = output.view(-1, ntokens)\n","            total_loss += seq_len * criterion(output_flat, targets).item()\n","    return total_loss / (len(eval_data) - 1)"]},{"cell_type":"markdown","metadata":{"id":"bPUDUvFBoCBW"},"source":["에포크 내에서 반복됩니다. 만약 검증 오차(validation loss) 가 우리가\n","지금까지 관찰한 것 중 최적이라면 모델을 저장합니다. 매 에포크 이후에\n","학습률을 조절합니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0modeCxoCBW"},"outputs":[],"source":["best_val_loss = float('inf')\n","epochs = 3\n","\n","with TemporaryDirectory() as tempdir:\n","    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n","\n","    for epoch in range(1, epochs + 1):\n","        epoch_start_time = time.time()\n","        train(model)\n","        val_loss = evaluate(model, val_data)\n","        val_ppl = math.exp(val_loss)\n","        elapsed = time.time() - epoch_start_time\n","        print('-' * 89)\n","        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n","            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n","        print('-' * 89)\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), best_model_params_path)\n","\n","        scheduler.step()\n","    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"]},{"cell_type":"markdown","metadata":{"id":"HFOQihxOoCBW"},"source":["평가 데이터셋(test dataset)으로 모델을 평가하기\n","===============================================\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D-1Qn3kIoCBW"},"outputs":[],"source":["test_loss = evaluate(model, test_data)\n","test_ppl = math.exp(test_loss)\n","print('=' * 89)\n","print(f'| End of training | test loss {test_loss:5.2f} | '\n","      f'test ppl {test_ppl:8.2f}')\n","print('=' * 89)"]}]}